{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Virtual Concierge\n",
    "\n",
    "## Compile Pretrained MXNET model with NEO\n",
    "\n",
    "In this notebook we will download a pre-trained MXNET model and compile for `ml_m4` and `deeplens` targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download pre-trained model if haven't already created from previous notebook\n",
    "import os\n",
    "\n",
    "if not os.path.exists('model.tar.gz'):\n",
    "    !aws s3 cp s3://deeplens-virtual-concierge-model/mobilefacenet/model.tar.gz ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invoke Neo Compilation API\n",
    "\n",
    "We then forward the model artifact to Neo Compilation API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import time\n",
    "from sagemaker.utils import name_from_base\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "sess = sagemaker.Session()\n",
    "region = sess.boto_region_name\n",
    "bucket = sess.default_bucket()\n",
    "\n",
    "compilation_job_name = name_from_base('virtual-concierge')\n",
    "\n",
    "model_key = '{}/model/model.tar.gz'.format(compilation_job_name)\n",
    "model_path = 's3://{}/{}'.format(bucket, model_key)\n",
    "boto3.resource('s3').Bucket(bucket).upload_file('model.tar.gz', model_key)\n",
    "\n",
    "sm_client = boto3.client('sagemaker')\n",
    "data_shape = '{\"data\":[1,3,112,112]}'\n",
    "target_device = 'ml_m4'\n",
    "framework = 'MXNET'\n",
    "framework_version = '1.2'\n",
    "compiled_model_path = 's3://{}/{}/output'.format(bucket, compilation_job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = sm_client.create_compilation_job(\n",
    "    CompilationJobName=compilation_job_name,\n",
    "    RoleArn=role,\n",
    "    InputConfig={\n",
    "        'S3Uri': model_path,\n",
    "        'DataInputConfig': data_shape,\n",
    "        'Framework': framework\n",
    "    },\n",
    "    OutputConfig={\n",
    "        'S3OutputLocation': compiled_model_path,\n",
    "        'TargetDevice': target_device\n",
    "    },\n",
    "    StoppingCondition={\n",
    "        'MaxRuntimeInSeconds': 300\n",
    "    }\n",
    ")\n",
    "print(response)\n",
    "\n",
    "# Poll every 30 sec\n",
    "while True:\n",
    "    response = sm_client.describe_compilation_job(CompilationJobName=compilation_job_name)\n",
    "    if response['CompilationJobStatus'] == 'COMPLETED':\n",
    "        break\n",
    "    elif response['CompilationJobStatus'] == 'FAILED':\n",
    "        raise RuntimeError('Compilation failed')\n",
    "    print('Compiling ...')\n",
    "    time.sleep(30)\n",
    "print('Done!')\n",
    "\n",
    "# Extract compiled model artifact\n",
    "compiled_model_path = response['ModelArtifacts']['S3ModelArtifacts']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create prediction endpoint\n",
    "\n",
    "To create a prediction endpoint, we first specify two additional functions, to be used with Neo Deep Learning Runtime:\n",
    "\n",
    "* `neo_preprocess(payload, content_type)`: Function that takes in the payload and Content-Type of each incoming request and returns a NumPy array. Here, the payload is byte-encoded NumPy array, so the function simply decodes the bytes to obtain the NumPy array.\n",
    "* `neo_postprocess(result)`: Function that takes the prediction results produced by Deep Learining Runtime and returns the response body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pygmentize predict.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload the Python script containing the two functions to S3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "\n",
    "source_key = '{}/source/sourcedir.tar.gz'.format(compilation_job_name)\n",
    "source_path = 's3://{}/{}'.format(bucket, source_key)\n",
    "\n",
    "with tarfile.open('sourcedir.tar.gz', 'w:gz') as f:\n",
    "    f.add('predict.py')\n",
    "\n",
    "boto3.resource('s3').Bucket(bucket).upload_file('sourcedir.tar.gz', source_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then create a SageMaker model record:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model import NEO_IMAGE_ACCOUNT\n",
    "from sagemaker.fw_utils import create_image_uri\n",
    "\n",
    "model_name = name_from_base('virtual-concierge') + target_device.replace('_', '-')\n",
    "\n",
    "image_uri = create_image_uri(region, 'neo-' + framework.lower(), target_device.replace('_', '.'),\n",
    "                             framework_version, py_version='py3', account=NEO_IMAGE_ACCOUNT[region])\n",
    "\n",
    "response = sm_client.create_model(\n",
    "    ModelName=model_name,\n",
    "    PrimaryContainer={\n",
    "        'Image': image_uri,\n",
    "        'ModelDataUrl': compiled_model_path,\n",
    "        'Environment': { 'SAGEMAKER_SUBMIT_DIRECTORY': source_path }\n",
    "    },\n",
    "    ExecutionRoleArn=role\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we create an Endpoint Configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_name = model_name\n",
    "\n",
    "response = sm_client.create_endpoint_config(\n",
    "    EndpointConfigName=config_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            'VariantName': 'default-variant-name',\n",
    "            'ModelName': model_name,\n",
    "            'InitialInstanceCount': 1,\n",
    "            'InstanceType': 'ml.m4.xlarge',\n",
    "            'InitialVariantWeight': 1.0\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we create an Endpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = model_name\n",
    "\n",
    "response = sm_client.create_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    EndpointConfigName=config_name,\n",
    ")\n",
    "print(response)\n",
    "\n",
    "print('Creating endpoint ...')\n",
    "sm_client.get_waiter('endpoint_in_service').wait(EndpointName=endpoint_name)\n",
    "\n",
    "response = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send requests\n",
    "\n",
    "Download a sample picture, detect the first face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import base64\n",
    "import io\n",
    "import PIL.Image\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "\n",
    "# Read image from s3\n",
    "image = {\n",
    "    'S3Object': {\n",
    "        'Bucket': 'aiml-lab-sagemaker',\n",
    "        'Name': 'politicians/politicians2.jpg'\n",
    "    }\n",
    "}\n",
    "\n",
    "image_object = s3.Object(image['S3Object']['Bucket'] , image['S3Object']['Name'])\n",
    "payload = image_object.get()['Body'].read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send the payload to the endpoint, and output the face embedding response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "sm_runtime = boto3.Session().client('sagemaker-runtime')\n",
    "\n",
    "response = sm_runtime.invoke_endpoint(EndpointName=endpoint_name,\n",
    "                                      ContentType='application/x-image',\n",
    "                                      Body=payload)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(json.loads(response['Body'].read().decode()))[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-process the payload to add the BoundaryBox and Roll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import base64\n",
    "import numpy as np\n",
    "\n",
    "rekognition = boto3.client('rekognition')\n",
    "    \n",
    "# Call rekognition to get bbox\n",
    "ret = rekognition.detect_faces(\n",
    "    Image={\n",
    "        'Bytes': payload\n",
    "    },\n",
    "    Attributes=['DEFAULT'],\n",
    ")\n",
    "\n",
    "bbox, roll = ret['FaceDetails'][0]['BoundingBox'],  round(ret['FaceDetails'][0]['Pose']['Roll']/90)*90\n",
    "print(bbox, roll)\n",
    "\n",
    "event = { \n",
    "    'Image': { 'Bytes': str(base64.b64encode(payload), 'utf-8') },\n",
    "    'BoundingBox': bbox, \n",
    "    'Roll': roll,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "sm_runtime = boto3.Session().client('sagemaker-runtime')\n",
    "\n",
    "response = sm_runtime.invoke_endpoint(EndpointName=endpoint_name,\n",
    "                                      ContentType='application/json',\n",
    "                                      Body=json.dumps(event))\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up\n",
    "\n",
    "Tear down the Neo endpoint, configuration and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_client.delete_endpoint(EndpointName=endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_client.delete_endpoint_config(EndpointConfigName=config_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_client.delete_model(ModelName=model_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
